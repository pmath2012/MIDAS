Logging to /tmp/openai-2025-06-21-19-36-57-072262
World Size : 1
Creating conditional model and diffusion process...
/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
Creating data loader for medical images...
Training for modality_conversion
Starting training loop...
loading model from checkpoint: /mnt/recsys/prateek/models/controlled_diff_ct2mri/model285000.pt...
loading optimizer state from checkpoint: /mnt/recsys/prateek/models/controlled_diff_ct2mri/opt285000.pt
loading EMA from checkpoint: /mnt/recsys/prateek/models/controlled_diff_ct2mri/ema_0.9999_285000.pt...
loading EMA from checkpoint: /mnt/recsys/prateek/models/controlled_diff_ct2mri/ema_0.9999_285000.pt...
------------------------
| grad_norm | 3        |
| loss      | 3.85     |
| loss_q1   | 3.85     |
| loss_q2   | 3.85     |
| loss_q3   | 3.85     |
| samples   | 3.42e+06 |
| step      | 2.85e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 2.86     |
| loss      | 3.61     |
| loss_q0   | 3.62     |
| loss_q1   | 3.61     |
| loss_q2   | 3.6      |
| loss_q3   | 3.6      |
| samples   | 3.43e+06 |
| step      | 2.86e+05 |
------------------------
------------------------
| grad_norm | 2.49     |
| loss      | 3.24     |
| loss_q0   | 3.25     |
| loss_q1   | 3.24     |
| loss_q2   | 3.23     |
| loss_q3   | 3.23     |
| samples   | 3.44e+06 |
| step      | 2.87e+05 |
------------------------
------------------------
| grad_norm | 2.24     |
| loss      | 2.98     |
| loss_q0   | 2.97     |
| loss_q1   | 2.99     |
| loss_q2   | 2.98     |
| loss_q3   | 2.97     |
| samples   | 3.46e+06 |
| step      | 2.88e+05 |
------------------------
------------------------
| grad_norm | 2.06     |
| loss      | 2.74     |
| loss_q0   | 2.74     |
| loss_q1   | 2.73     |
| loss_q2   | 2.72     |
| loss_q3   | 2.77     |
| samples   | 3.47e+06 |
| step      | 2.89e+05 |
------------------------
------------------------
| grad_norm | 1.89     |
| loss      | 2.5      |
| loss_q0   | 2.52     |
| loss_q1   | 2.5      |
| loss_q2   | 2.49     |
| loss_q3   | 2.51     |
| samples   | 3.48e+06 |
| step      | 2.9e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.75     |
| loss      | 2.32     |
| loss_q0   | 2.33     |
| loss_q1   | 2.31     |
| loss_q2   | 2.32     |
| loss_q3   | 2.31     |
| samples   | 3.49e+06 |
| step      | 2.91e+05 |
------------------------
------------------------
| grad_norm | 1.64     |
| loss      | 2.13     |
| loss_q0   | 2.15     |
| loss_q1   | 2.11     |
| loss_q2   | 2.12     |
| loss_q3   | 2.15     |
| samples   | 3.5e+06  |
| step      | 2.92e+05 |
------------------------
------------------------
| grad_norm | 1.56     |
| loss      | 1.98     |
| loss_q0   | 1.96     |
| loss_q1   | 1.98     |
| loss_q2   | 1.98     |
| loss_q3   | 2.01     |
| samples   | 3.52e+06 |
| step      | 2.93e+05 |
------------------------
------------------------
| grad_norm | 1.45     |
| loss      | 1.79     |
| loss_q0   | 1.79     |
| loss_q1   | 1.78     |
| loss_q2   | 1.81     |
| loss_q3   | 1.79     |
| samples   | 3.53e+06 |
| step      | 2.94e+05 |
------------------------
------------------------
| grad_norm | 1.41     |
| loss      | 1.68     |
| loss_q0   | 1.67     |
| loss_q1   | 1.66     |
| loss_q2   | 1.7      |
| loss_q3   | 1.67     |
| samples   | 3.54e+06 |
| step      | 2.95e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.35     |
| loss      | 1.53     |
| loss_q0   | 1.53     |
| loss_q1   | 1.52     |
| loss_q2   | 1.54     |
| loss_q3   | 1.52     |
| samples   | 3.55e+06 |
| step      | 2.96e+05 |
------------------------
------------------------
| grad_norm | 1.3      |
| loss      | 1.41     |
| loss_q0   | 1.39     |
| loss_q1   | 1.43     |
| loss_q2   | 1.4      |
| loss_q3   | 1.42     |
| samples   | 3.56e+06 |
| step      | 2.97e+05 |
------------------------
------------------------
| grad_norm | 1.27     |
| loss      | 1.27     |
| loss_q0   | 1.27     |
| loss_q1   | 1.28     |
| loss_q2   | 1.28     |
| loss_q3   | 1.26     |
| samples   | 3.58e+06 |
| step      | 2.98e+05 |
------------------------
------------------------
| grad_norm | 1.25     |
| loss      | 1.18     |
| loss_q0   | 1.19     |
| loss_q1   | 1.18     |
| loss_q2   | 1.17     |
| loss_q3   | 1.18     |
| samples   | 3.59e+06 |
| step      | 2.99e+05 |
------------------------
------------------------
| grad_norm | 1.23     |
| loss      | 1.07     |
| loss_q0   | 1.08     |
| loss_q1   | 1.06     |
| loss_q2   | 1.08     |
| loss_q3   | 1.07     |
| samples   | 3.6e+06  |
| step      | 3e+05    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.2      |
| loss      | 0.933    |
| loss_q0   | 0.951    |
| loss_q1   | 0.907    |
| loss_q2   | 0.944    |
| loss_q3   | 0.933    |
| samples   | 3.61e+06 |
| step      | 3.01e+05 |
------------------------
------------------------
| grad_norm | 1.2      |
| loss      | 0.84     |
| loss_q0   | 0.832    |
| loss_q1   | 0.839    |
| loss_q2   | 0.832    |
| loss_q3   | 0.858    |
| samples   | 3.62e+06 |
| step      | 3.02e+05 |
------------------------
------------------------
| grad_norm | 1.18     |
| loss      | 0.728    |
| loss_q0   | 0.742    |
| loss_q1   | 0.722    |
| loss_q2   | 0.73     |
| loss_q3   | 0.72     |
| samples   | 3.64e+06 |
| step      | 3.03e+05 |
------------------------
------------------------
| grad_norm | 1.17     |
| loss      | 0.635    |
| loss_q0   | 0.617    |
| loss_q1   | 0.631    |
| loss_q2   | 0.636    |
| loss_q3   | 0.655    |
| samples   | 3.65e+06 |
| step      | 3.04e+05 |
------------------------
------------------------
| grad_norm | 1.18     |
| loss      | 0.523    |
| loss_q0   | 0.522    |
| loss_q1   | 0.508    |
| loss_q2   | 0.547    |
| loss_q3   | 0.517    |
| samples   | 3.66e+06 |
| step      | 3.05e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.17     |
| loss      | 0.435    |
| loss_q0   | 0.437    |
| loss_q1   | 0.432    |
| loss_q2   | 0.435    |
| loss_q3   | 0.436    |
| samples   | 3.67e+06 |
| step      | 3.06e+05 |
------------------------
------------------------
| grad_norm | 1.17     |
| loss      | 0.331    |
| loss_q0   | 0.336    |
| loss_q1   | 0.328    |
| loss_q2   | 0.334    |
| loss_q3   | 0.327    |
| samples   | 3.68e+06 |
| step      | 3.07e+05 |
------------------------
------------------------
| grad_norm | 1.16     |
| loss      | 0.216    |
| loss_q0   | 0.228    |
| loss_q1   | 0.213    |
| loss_q2   | 0.2      |
| loss_q3   | 0.222    |
| samples   | 3.7e+06  |
| step      | 3.08e+05 |
------------------------
------------------------
| grad_norm | 1.16     |
| loss      | 0.136    |
| loss_q0   | 0.134    |
| loss_q1   | 0.116    |
| loss_q2   | 0.149    |
| loss_q3   | 0.146    |
| samples   | 3.71e+06 |
| step      | 3.09e+05 |
------------------------
------------------------
| grad_norm | 1.17     |
| loss      | 0.0405   |
| loss_q0   | 0.0398   |
| loss_q1   | 0.0347   |
| loss_q2   | 0.0404   |
| loss_q3   | 0.0468   |
| samples   | 3.72e+06 |
| step      | 3.1e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.17     |
| loss      | -0.0711  |
| loss_q0   | -0.0619  |
| loss_q1   | -0.0782  |
| loss_q2   | -0.0623  |
| loss_q3   | -0.082   |
| samples   | 3.73e+06 |
| step      | 3.11e+05 |
------------------------
------------------------
| grad_norm | 1.16     |
| loss      | -0.166   |
| loss_q0   | -0.177   |
| loss_q1   | -0.157   |
| loss_q2   | -0.17    |
| loss_q3   | -0.16    |
| samples   | 3.74e+06 |
| step      | 3.12e+05 |
------------------------
------------------------
| grad_norm | 1.16     |
| loss      | -0.269   |
| loss_q0   | -0.271   |
| loss_q1   | -0.266   |
| loss_q2   | -0.292   |
| loss_q3   | -0.246   |
| samples   | 3.76e+06 |
| step      | 3.13e+05 |
------------------------
------------------------
| grad_norm | 1.17     |
| loss      | -0.364   |
| loss_q0   | -0.35    |
| loss_q1   | -0.375   |
| loss_q2   | -0.368   |
| loss_q3   | -0.366   |
| samples   | 3.77e+06 |
| step      | 3.14e+05 |
------------------------
------------------------
| grad_norm | 1.17     |
| loss      | -0.463   |
| loss_q0   | -0.44    |
| loss_q1   | -0.466   |
| loss_q2   | -0.482   |
| loss_q3   | -0.463   |
| samples   | 3.78e+06 |
| step      | 3.15e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.19     |
| loss      | -0.546   |
| loss_q0   | -0.536   |
| loss_q1   | -0.549   |
| loss_q2   | -0.565   |
| loss_q3   | -0.533   |
| samples   | 3.79e+06 |
| step      | 3.16e+05 |
------------------------
------------------------
| grad_norm | 1.2      |
| loss      | -0.662   |
| loss_q0   | -0.662   |
| loss_q1   | -0.667   |
| loss_q2   | -0.678   |
| loss_q3   | -0.643   |
| samples   | 3.8e+06  |
| step      | 3.17e+05 |
------------------------
------------------------
| grad_norm | 1.19     |
| loss      | -0.753   |
| loss_q0   | -0.76    |
| loss_q1   | -0.749   |
| loss_q2   | -0.743   |
| loss_q3   | -0.759   |
| samples   | 3.82e+06 |
| step      | 3.18e+05 |
------------------------
------------------------
| grad_norm | 1.22     |
| loss      | -0.849   |
| loss_q0   | -0.845   |
| loss_q1   | -0.842   |
| loss_q2   | -0.853   |
| loss_q3   | -0.856   |
| samples   | 3.83e+06 |
| step      | 3.19e+05 |
------------------------
------------------------
| grad_norm | 1.25     |
| loss      | -0.94    |
| loss_q0   | -0.919   |
| loss_q1   | -0.949   |
| loss_q2   | -0.97    |
| loss_q3   | -0.921   |
| samples   | 3.84e+06 |
| step      | 3.2e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.25     |
| loss      | -1.04    |
| loss_q0   | -1.02    |
| loss_q1   | -1.04    |
| loss_q2   | -1.05    |
| loss_q3   | -1.03    |
| samples   | 3.85e+06 |
| step      | 3.21e+05 |
------------------------
------------------------
| grad_norm | 1.28     |
| loss      | -1.14    |
| loss_q0   | -1.13    |
| loss_q1   | -1.13    |
| loss_q2   | -1.14    |
| loss_q3   | -1.14    |
| samples   | 3.86e+06 |
| step      | 3.22e+05 |
------------------------
------------------------
| grad_norm | 1.3      |
| loss      | -1.23    |
| loss_q0   | -1.24    |
| loss_q1   | -1.23    |
| loss_q2   | -1.24    |
| loss_q3   | -1.23    |
| samples   | 3.88e+06 |
| step      | 3.23e+05 |
------------------------
------------------------
| grad_norm | 1.36     |
| loss      | -1.31    |
| loss_q0   | -1.32    |
| loss_q1   | -1.32    |
| loss_q2   | -1.31    |
| loss_q3   | -1.3     |
| samples   | 3.89e+06 |
| step      | 3.24e+05 |
------------------------
------------------------
| grad_norm | 1.41     |
| loss      | -1.42    |
| loss_q0   | -1.42    |
| loss_q1   | -1.42    |
| loss_q2   | -1.42    |
| loss_q3   | -1.41    |
| samples   | 3.9e+06  |
| step      | 3.25e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.44     |
| loss      | -1.51    |
| loss_q0   | -1.5     |
| loss_q1   | -1.51    |
| loss_q2   | -1.51    |
| loss_q3   | -1.52    |
| samples   | 3.91e+06 |
| step      | 3.26e+05 |
------------------------
------------------------
| grad_norm | 1.47     |
| loss      | -1.59    |
| loss_q0   | -1.58    |
| loss_q1   | -1.61    |
| loss_q2   | -1.58    |
| loss_q3   | -1.6     |
| samples   | 3.92e+06 |
| step      | 3.27e+05 |
------------------------
------------------------
| grad_norm | 1.55     |
| loss      | -1.69    |
| loss_q0   | -1.67    |
| loss_q1   | -1.7     |
| loss_q2   | -1.7     |
| loss_q3   | -1.7     |
| samples   | 3.94e+06 |
| step      | 3.28e+05 |
------------------------
------------------------
| grad_norm | 1.54     |
| loss      | -1.78    |
| loss_q0   | -1.78    |
| loss_q1   | -1.79    |
| loss_q2   | -1.79    |
| loss_q3   | -1.78    |
| samples   | 3.95e+06 |
| step      | 3.29e+05 |
------------------------
------------------------
| grad_norm | 1.73     |
| loss      | -1.87    |
| loss_q0   | -1.85    |
| loss_q1   | -1.86    |
| loss_q2   | -1.88    |
| loss_q3   | -1.88    |
| samples   | 3.96e+06 |
| step      | 3.3e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.8      |
| loss      | -1.97    |
| loss_q0   | -1.96    |
| loss_q1   | -1.96    |
| loss_q2   | -1.99    |
| loss_q3   | -1.95    |
| samples   | 3.97e+06 |
| step      | 3.31e+05 |
------------------------
------------------------
| grad_norm | 1.97     |
| loss      | -2.04    |
| loss_q0   | -2.03    |
| loss_q1   | -2.05    |
| loss_q2   | -2.05    |
| loss_q3   | -2.04    |
| samples   | 3.98e+06 |
| step      | 3.32e+05 |
------------------------
------------------------
| grad_norm | 1.98     |
| loss      | -2.11    |
| loss_q0   | -2.08    |
| loss_q1   | -2.12    |
| loss_q2   | -2.14    |
| loss_q3   | -2.12    |
| samples   | 4e+06    |
| step      | 3.33e+05 |
------------------------
------------------------
| grad_norm | 2.21     |
| loss      | -2.22    |
| loss_q0   | -2.2     |
| loss_q1   | -2.22    |
| loss_q2   | -2.23    |
| loss_q3   | -2.21    |
| samples   | 4.01e+06 |
| step      | 3.34e+05 |
------------------------
------------------------
| grad_norm | 2.44     |
| loss      | -2.28    |
| loss_q0   | -2.27    |
| loss_q1   | -2.29    |
| loss_q2   | -2.29    |
| loss_q3   | -2.28    |
| samples   | 4.02e+06 |
| step      | 3.35e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 2.51     |
| loss      | -2.38    |
| loss_q0   | -2.34    |
| loss_q1   | -2.4     |
| loss_q2   | -2.38    |
| loss_q3   | -2.39    |
| samples   | 4.03e+06 |
| step      | 3.36e+05 |
------------------------
------------------------
| grad_norm | 2.71     |
| loss      | -2.45    |
| loss_q0   | -2.45    |
| loss_q1   | -2.44    |
| loss_q2   | -2.45    |
| loss_q3   | -2.45    |
| samples   | 4.04e+06 |
| step      | 3.37e+05 |
------------------------
------------------------
| grad_norm | 2.93     |
| loss      | -2.52    |
| loss_q0   | -2.5     |
| loss_q1   | -2.53    |
| loss_q2   | -2.53    |
| loss_q3   | -2.54    |
| samples   | 4.06e+06 |
| step      | 3.38e+05 |
------------------------
------------------------
| grad_norm | 2.99     |
| loss      | -2.62    |
| loss_q0   | -2.59    |
| loss_q1   | -2.65    |
| loss_q2   | -2.61    |
| loss_q3   | -2.61    |
| samples   | 4.07e+06 |
| step      | 3.39e+05 |
------------------------
------------------------
| grad_norm | 3.45     |
| loss      | -2.69    |
| loss_q0   | -2.67    |
| loss_q1   | -2.69    |
| loss_q2   | -2.7     |
| loss_q3   | -2.69    |
| samples   | 4.08e+06 |
| step      | 3.4e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 3.63     |
| loss      | -2.75    |
| loss_q0   | -2.71    |
| loss_q1   | -2.77    |
| loss_q2   | -2.77    |
| loss_q3   | -2.74    |
| samples   | 4.09e+06 |
| step      | 3.41e+05 |
------------------------
------------------------
| grad_norm | 3.74     |
| loss      | -2.82    |
| loss_q0   | -2.79    |
| loss_q1   | -2.82    |
| loss_q2   | -2.83    |
| loss_q3   | -2.84    |
| samples   | 4.1e+06  |
| step      | 3.42e+05 |
------------------------
------------------------
| grad_norm | 4        |
| loss      | -2.9     |
| loss_q0   | -2.86    |
| loss_q1   | -2.91    |
| loss_q2   | -2.91    |
| loss_q3   | -2.91    |
| samples   | 4.12e+06 |
| step      | 3.43e+05 |
------------------------
------------------------
| grad_norm | 4.2      |
| loss      | -2.96    |
| loss_q0   | -2.91    |
| loss_q1   | -2.99    |
| loss_q2   | -2.98    |
| loss_q3   | -2.96    |
| samples   | 4.13e+06 |
| step      | 3.44e+05 |
------------------------
------------------------
| grad_norm | 4.94     |
| loss      | -3.04    |
| loss_q0   | -3.03    |
| loss_q1   | -3.05    |
| loss_q2   | -3.04    |
| loss_q3   | -3.04    |
| samples   | 4.14e+06 |
| step      | 3.45e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 4.83     |
| loss      | -3.11    |
| loss_q0   | -3.05    |
| loss_q1   | -3.13    |
| loss_q2   | -3.13    |
| loss_q3   | -3.13    |
| samples   | 4.15e+06 |
| step      | 3.46e+05 |
------------------------
------------------------
| grad_norm | 5.45     |
| loss      | -3.18    |
| loss_q0   | -3.14    |
| loss_q1   | -3.19    |
| loss_q2   | -3.18    |
| loss_q3   | -3.2     |
| samples   | 4.16e+06 |
| step      | 3.47e+05 |
------------------------
------------------------
| grad_norm | 6.33     |
| loss      | -3.22    |
| loss_q0   | -3.18    |
| loss_q1   | -3.23    |
| loss_q2   | -3.25    |
| loss_q3   | -3.23    |
| samples   | 4.18e+06 |
| step      | 3.48e+05 |
------------------------
------------------------
| grad_norm | 6.7      |
| loss      | -3.28    |
| loss_q0   | -3.23    |
| loss_q1   | -3.29    |
| loss_q2   | -3.3     |
| loss_q3   | -3.29    |
| samples   | 4.19e+06 |
| step      | 3.49e+05 |
------------------------
------------------------
| grad_norm | 7.26     |
| loss      | -3.34    |
| loss_q0   | -3.29    |
| loss_q1   | -3.35    |
| loss_q2   | -3.37    |
| loss_q3   | -3.37    |
| samples   | 4.2e+06  |
| step      | 3.5e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 7.34     |
| loss      | -3.39    |
| loss_q0   | -3.31    |
| loss_q1   | -3.43    |
| loss_q2   | -3.42    |
| loss_q3   | -3.39    |
| samples   | 4.21e+06 |
| step      | 3.51e+05 |
------------------------
------------------------
| grad_norm | 7.95     |
| loss      | -3.45    |
| loss_q0   | -3.39    |
| loss_q1   | -3.46    |
| loss_q2   | -3.46    |
| loss_q3   | -3.47    |
| samples   | 4.22e+06 |
| step      | 3.52e+05 |
------------------------
------------------------
| grad_norm | 8.99     |
| loss      | -3.47    |
| loss_q0   | -3.38    |
| loss_q1   | -3.51    |
| loss_q2   | -3.52    |
| loss_q3   | -3.49    |
| samples   | 4.24e+06 |
| step      | 3.53e+05 |
------------------------
------------------------
| grad_norm | 9.5      |
| loss      | -3.51    |
| loss_q0   | -3.41    |
| loss_q1   | -3.55    |
| loss_q2   | -3.53    |
| loss_q3   | -3.54    |
| samples   | 4.25e+06 |
| step      | 3.54e+05 |
------------------------
------------------------
| grad_norm | 9.86     |
| loss      | -3.57    |
| loss_q0   | -3.49    |
| loss_q1   | -3.59    |
| loss_q2   | -3.6     |
| loss_q3   | -3.6     |
| samples   | 4.26e+06 |
| step      | 3.55e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 11.1     |
| loss      | -3.61    |
| loss_q0   | -3.52    |
| loss_q1   | -3.63    |
| loss_q2   | -3.66    |
| loss_q3   | -3.64    |
| samples   | 4.27e+06 |
| step      | 3.56e+05 |
------------------------
------------------------
| grad_norm | 11.4     |
| loss      | -3.66    |
| loss_q0   | -3.58    |
| loss_q1   | -3.7     |
| loss_q2   | -3.68    |
| loss_q3   | -3.69    |
| samples   | 4.28e+06 |
| step      | 3.57e+05 |
------------------------
------------------------
| grad_norm | 12       |
| loss      | -3.66    |
| loss_q0   | -3.55    |
| loss_q1   | -3.7     |
| loss_q2   | -3.68    |
| loss_q3   | -3.7     |
| samples   | 4.3e+06  |
| step      | 3.58e+05 |
------------------------
------------------------
| grad_norm | 12.5     |
| loss      | -3.73    |
| loss_q0   | -3.62    |
| loss_q1   | -3.76    |
| loss_q2   | -3.77    |
| loss_q3   | -3.77    |
| samples   | 4.31e+06 |
| step      | 3.59e+05 |
------------------------
------------------------
| grad_norm | 13.7     |
| loss      | -3.7     |
| loss_q0   | -3.54    |
| loss_q1   | -3.76    |
| loss_q2   | -3.74    |
| loss_q3   | -3.75    |
| samples   | 4.32e+06 |
| step      | 3.6e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 14.9     |
| loss      | -3.76    |
| loss_q0   | -3.62    |
| loss_q1   | -3.78    |
| loss_q2   | -3.82    |
| loss_q3   | -3.82    |
| samples   | 4.33e+06 |
| step      | 3.61e+05 |
------------------------
------------------------
| grad_norm | 15.7     |
| loss      | -3.79    |
| loss_q0   | -3.68    |
| loss_q1   | -3.84    |
| loss_q2   | -3.83    |
| loss_q3   | -3.83    |
| samples   | 4.34e+06 |
| step      | 3.62e+05 |
------------------------
------------------------
| grad_norm | 15.8     |
| loss      | -3.82    |
| loss_q0   | -3.68    |
| loss_q1   | -3.86    |
| loss_q2   | -3.88    |
| loss_q3   | -3.85    |
| samples   | 4.36e+06 |
| step      | 3.63e+05 |
------------------------
------------------------
| grad_norm | 17.3     |
| loss      | -3.8     |
| loss_q0   | -3.62    |
| loss_q1   | -3.87    |
| loss_q2   | -3.86    |
| loss_q3   | -3.84    |
| samples   | 4.37e+06 |
| step      | 3.64e+05 |
------------------------
------------------------
| grad_norm | 16.7     |
| loss      | -3.8     |
| loss_q0   | -3.63    |
| loss_q1   | -3.86    |
| loss_q2   | -3.87    |
| loss_q3   | -3.84    |
| samples   | 4.38e+06 |
| step      | 3.65e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 18.2     |
| loss      | -3.87    |
| loss_q0   | -3.72    |
| loss_q1   | -3.95    |
| loss_q2   | -3.89    |
| loss_q3   | -3.94    |
| samples   | 4.39e+06 |
| step      | 3.66e+05 |
------------------------
------------------------
| grad_norm | 17.9     |
| loss      | -3.83    |
| loss_q0   | -3.65    |
| loss_q1   | -3.92    |
| loss_q2   | -3.88    |
| loss_q3   | -3.86    |
| samples   | 4.4e+06  |
| step      | 3.67e+05 |
------------------------
------------------------
| grad_norm | 19       |
| loss      | -3.86    |
| loss_q0   | -3.71    |
| loss_q1   | -3.89    |
| loss_q2   | -3.91    |
| loss_q3   | -3.91    |
| samples   | 4.42e+06 |
| step      | 3.68e+05 |
------------------------
------------------------
| grad_norm | 18.9     |
| loss      | -3.83    |
| loss_q0   | -3.6     |
| loss_q1   | -3.87    |
| loss_q2   | -3.92    |
| loss_q3   | -3.92    |
| samples   | 4.43e+06 |
| step      | 3.69e+05 |
------------------------
------------------------
| grad_norm | 19.2     |
| loss      | -3.86    |
| loss_q0   | -3.66    |
| loss_q1   | -3.93    |
| loss_q2   | -3.92    |
| loss_q3   | -3.93    |
| samples   | 4.44e+06 |
| step      | 3.7e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 21       |
| loss      | -3.85    |
| loss_q0   | -3.65    |
| loss_q1   | -3.88    |
| loss_q2   | -3.93    |
| loss_q3   | -3.93    |
| samples   | 4.45e+06 |
| step      | 3.71e+05 |
------------------------
------------------------
| grad_norm | 20.1     |
| loss      | -3.89    |
| loss_q0   | -3.7     |
| loss_q1   | -3.98    |
| loss_q2   | -3.93    |
| loss_q3   | -3.94    |
| samples   | 4.46e+06 |
| step      | 3.72e+05 |
------------------------
------------------------
| grad_norm | 20.7     |
| loss      | -3.93    |
| loss_q0   | -3.75    |
| loss_q1   | -3.98    |
| loss_q2   | -4       |
| loss_q3   | -3.99    |
| samples   | 4.48e+06 |
| step      | 3.73e+05 |
------------------------
------------------------
| grad_norm | 21.4     |
| loss      | -3.88    |
| loss_q0   | -3.68    |
| loss_q1   | -3.94    |
| loss_q2   | -3.94    |
| loss_q3   | -3.96    |
| samples   | 4.49e+06 |
| step      | 3.74e+05 |
------------------------
------------------------
| grad_norm | 22.5     |
| loss      | -3.9     |
| loss_q0   | -3.7     |
| loss_q1   | -3.98    |
| loss_q2   | -3.95    |
| loss_q3   | -3.98    |
| samples   | 4.5e+06  |
| step      | 3.75e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 21.9     |
| loss      | -3.89    |
| loss_q0   | -3.68    |
| loss_q1   | -3.95    |
| loss_q2   | -3.95    |
| loss_q3   | -3.98    |
| samples   | 4.51e+06 |
| step      | 3.76e+05 |
------------------------
------------------------
| grad_norm | 22.2     |
| loss      | -3.92    |
| loss_q0   | -3.72    |
| loss_q1   | -3.98    |
| loss_q2   | -4       |
| loss_q3   | -3.99    |
| samples   | 4.52e+06 |
| step      | 3.77e+05 |
------------------------
------------------------
| grad_norm | 22.9     |
| loss      | -3.85    |
| loss_q0   | -3.62    |
| loss_q1   | -3.89    |
| loss_q2   | -3.95    |
| loss_q3   | -3.95    |
| samples   | 4.54e+06 |
| step      | 3.78e+05 |
------------------------
------------------------
| grad_norm | 21.6     |
| loss      | -3.94    |
| loss_q0   | -3.77    |
| loss_q1   | -4       |
| loss_q2   | -3.99    |
| loss_q3   | -4       |
| samples   | 4.55e+06 |
| step      | 3.79e+05 |
------------------------
------------------------
| grad_norm | 25.1     |
| loss      | -3.87    |
| loss_q0   | -3.67    |
| loss_q1   | -3.94    |
| loss_q2   | -3.96    |
| loss_q3   | -3.91    |
| samples   | 4.56e+06 |
| step      | 3.8e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.8     |
| loss      | -3.92    |
| loss_q0   | -3.72    |
| loss_q1   | -3.96    |
| loss_q2   | -3.99    |
| loss_q3   | -3.99    |
| samples   | 4.57e+06 |
| step      | 3.81e+05 |
------------------------
------------------------
| grad_norm | 24.1     |
| loss      | -3.92    |
| loss_q0   | -3.71    |
| loss_q1   | -3.99    |
| loss_q2   | -3.98    |
| loss_q3   | -4       |
| samples   | 4.58e+06 |
| step      | 3.82e+05 |
------------------------
------------------------
| grad_norm | 24.3     |
| loss      | -3.91    |
| loss_q0   | -3.67    |
| loss_q1   | -3.96    |
| loss_q2   | -3.99    |
| loss_q3   | -4       |
| samples   | 4.6e+06  |
| step      | 3.83e+05 |
------------------------
------------------------
| grad_norm | 23.4     |
| loss      | -3.88    |
| loss_q0   | -3.63    |
| loss_q1   | -3.92    |
| loss_q2   | -4       |
| loss_q3   | -3.96    |
| samples   | 4.61e+06 |
| step      | 3.84e+05 |
------------------------
------------------------
| grad_norm | 25       |
| loss      | -3.93    |
| loss_q0   | -3.68    |
| loss_q1   | -4       |
| loss_q2   | -4.01    |
| loss_q3   | -4.01    |
| samples   | 4.62e+06 |
| step      | 3.85e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 25.4     |
| loss      | -4       |
| loss_q0   | -3.77    |
| loss_q1   | -4.08    |
| loss_q2   | -4.08    |
| loss_q3   | -4.07    |
| samples   | 4.63e+06 |
| step      | 3.86e+05 |
------------------------
------------------------
| grad_norm | 25.8     |
| loss      | -3.93    |
| loss_q0   | -3.67    |
| loss_q1   | -4.02    |
| loss_q2   | -3.99    |
| loss_q3   | -4.03    |
| samples   | 4.64e+06 |
| step      | 3.87e+05 |
------------------------
------------------------
| grad_norm | 26.8     |
| loss      | -3.98    |
| loss_q0   | -3.76    |
| loss_q1   | -4.05    |
| loss_q2   | -4.04    |
| loss_q3   | -4.08    |
| samples   | 4.66e+06 |
| step      | 3.88e+05 |
------------------------
------------------------
| grad_norm | 25.5     |
| loss      | -3.89    |
| loss_q0   | -3.64    |
| loss_q1   | -3.94    |
| loss_q2   | -3.98    |
| loss_q3   | -4       |
| samples   | 4.67e+06 |
| step      | 3.89e+05 |
------------------------
------------------------
| grad_norm | 26.1     |
| loss      | -3.92    |
| loss_q0   | -3.72    |
| loss_q1   | -3.97    |
| loss_q2   | -3.99    |
| loss_q3   | -3.99    |
| samples   | 4.68e+06 |
| step      | 3.9e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 26       |
| loss      | -3.93    |
| loss_q0   | -3.72    |
| loss_q1   | -4.04    |
| loss_q2   | -4.02    |
| loss_q3   | -3.97    |
| samples   | 4.69e+06 |
| step      | 3.91e+05 |
------------------------
------------------------
| grad_norm | 26.2     |
| loss      | -3.94    |
| loss_q0   | -3.67    |
| loss_q1   | -4.04    |
| loss_q2   | -4.03    |
| loss_q3   | -4.02    |
| samples   | 4.7e+06  |
| step      | 3.92e+05 |
------------------------
------------------------
| grad_norm | 26.1     |
| loss      | -3.81    |
| loss_q0   | -3.57    |
| loss_q1   | -3.88    |
| loss_q2   | -3.93    |
| loss_q3   | -3.88    |
| samples   | 4.72e+06 |
| step      | 3.93e+05 |
------------------------
------------------------
| grad_norm | 25.4     |
| loss      | -3.82    |
| loss_q0   | -3.55    |
| loss_q1   | -3.87    |
| loss_q2   | -3.94    |
| loss_q3   | -3.92    |
| samples   | 4.73e+06 |
| step      | 3.94e+05 |
------------------------
------------------------
| grad_norm | 25.8     |
| loss      | -3.85    |
| loss_q0   | -3.59    |
| loss_q1   | -3.95    |
| loss_q2   | -3.93    |
| loss_q3   | -3.94    |
| samples   | 4.74e+06 |
| step      | 3.95e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 27.5     |
| loss      | -3.96    |
| loss_q0   | -3.77    |
| loss_q1   | -4.02    |
| loss_q2   | -4.05    |
| loss_q3   | -4.02    |
| samples   | 4.75e+06 |
| step      | 3.96e+05 |
------------------------
------------------------
| grad_norm | 26.3     |
| loss      | -3.91    |
| loss_q0   | -3.66    |
| loss_q1   | -4       |
| loss_q2   | -3.99    |
| loss_q3   | -3.99    |
| samples   | 4.76e+06 |
| step      | 3.97e+05 |
------------------------
------------------------
| grad_norm | 25.9     |
| loss      | -3.94    |
| loss_q0   | -3.66    |
| loss_q1   | -4.03    |
| loss_q2   | -4.02    |
| loss_q3   | -4.04    |
| samples   | 4.78e+06 |
| step      | 3.98e+05 |
------------------------
------------------------
| grad_norm | 27.9     |
| loss      | -3.86    |
| loss_q0   | -3.61    |
| loss_q1   | -3.9     |
| loss_q2   | -3.94    |
| loss_q3   | -3.99    |
| samples   | 4.79e+06 |
| step      | 3.99e+05 |
------------------------
------------------------
| grad_norm | 26.2     |
| loss      | -4.01    |
| loss_q0   | -3.84    |
| loss_q1   | -4.07    |
| loss_q2   | -4.06    |
| loss_q3   | -4.09    |
| samples   | 4.8e+06  |
| step      | 4e+05    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 27.9     |
| loss      | -3.9     |
| loss_q0   | -3.61    |
| loss_q1   | -3.99    |
| loss_q2   | -4.02    |
| loss_q3   | -3.98    |
| samples   | 4.81e+06 |
| step      | 4.01e+05 |
------------------------
------------------------
| grad_norm | 27.8     |
| loss      | -3.88    |
| loss_q0   | -3.61    |
| loss_q1   | -3.93    |
| loss_q2   | -3.99    |
| loss_q3   | -4       |
| samples   | 4.82e+06 |
| step      | 4.02e+05 |
------------------------
------------------------
| grad_norm | 26.6     |
| loss      | -3.9     |
| loss_q0   | -3.66    |
| loss_q1   | -3.95    |
| loss_q2   | -3.99    |
| loss_q3   | -4       |
| samples   | 4.84e+06 |
| step      | 4.03e+05 |
------------------------
------------------------
| grad_norm | 27.3     |
| loss      | -3.78    |
| loss_q0   | -3.47    |
| loss_q1   | -3.87    |
| loss_q2   | -3.88    |
| loss_q3   | -3.91    |
| samples   | 4.85e+06 |
| step      | 4.04e+05 |
------------------------
------------------------
| grad_norm | 27.8     |
| loss      | -4.02    |
| loss_q0   | -3.78    |
| loss_q1   | -4.12    |
| loss_q2   | -4.08    |
| loss_q3   | -4.1     |
| samples   | 4.86e+06 |
| step      | 4.05e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 27.2     |
| loss      | -3.95    |
| loss_q0   | -3.69    |
| loss_q1   | -4.02    |
| loss_q2   | -4       |
| loss_q3   | -4.06    |
| samples   | 4.87e+06 |
| step      | 4.06e+05 |
------------------------
------------------------
| grad_norm | 28.7     |
| loss      | -3.95    |
| loss_q0   | -3.67    |
| loss_q1   | -4.07    |
| loss_q2   | -4.03    |
| loss_q3   | -4.03    |
| samples   | 4.88e+06 |
| step      | 4.07e+05 |
------------------------
------------------------
| grad_norm | 28.3     |
| loss      | -3.88    |
| loss_q0   | -3.62    |
| loss_q1   | -3.93    |
| loss_q2   | -3.99    |
| loss_q3   | -3.98    |
| samples   | 4.9e+06  |
| step      | 4.08e+05 |
------------------------
------------------------
| grad_norm | 27.2     |
| loss      | -3.92    |
| loss_q0   | -3.67    |
| loss_q1   | -4.01    |
| loss_q2   | -4.02    |
| loss_q3   | -3.99    |
| samples   | 4.91e+06 |
| step      | 4.09e+05 |
------------------------
------------------------
| grad_norm | 27.6     |
| loss      | -3.87    |
| loss_q0   | -3.65    |
| loss_q1   | -3.89    |
| loss_q2   | -3.95    |
| loss_q3   | -3.98    |
| samples   | 4.92e+06 |
| step      | 4.1e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 27.1     |
| loss      | -3.9     |
| loss_q0   | -3.67    |
| loss_q1   | -3.94    |
| loss_q2   | -3.97    |
| loss_q3   | -4.01    |
| samples   | 4.93e+06 |
| step      | 4.11e+05 |
------------------------
------------------------
| grad_norm | 27.6     |
| loss      | -3.93    |
| loss_q0   | -3.74    |
| loss_q1   | -3.99    |
| loss_q2   | -3.97    |
| loss_q3   | -4.03    |
| samples   | 4.94e+06 |
| step      | 4.12e+05 |
------------------------
------------------------
| grad_norm | 27.5     |
| loss      | -3.94    |
| loss_q0   | -3.67    |
| loss_q1   | -3.97    |
| loss_q2   | -4.07    |
| loss_q3   | -4.06    |
| samples   | 4.96e+06 |
| step      | 4.13e+05 |
------------------------
------------------------
| grad_norm | 27.3     |
| loss      | -3.95    |
| loss_q0   | -3.71    |
| loss_q1   | -4.03    |
| loss_q2   | -4.04    |
| loss_q3   | -4.03    |
| samples   | 4.97e+06 |
| step      | 4.14e+05 |
------------------------
------------------------
| grad_norm | 28.1     |
| loss      | -3.92    |
| loss_q0   | -3.68    |
| loss_q1   | -3.98    |
| loss_q2   | -4.05    |
| loss_q3   | -3.98    |
| samples   | 4.98e+06 |
| step      | 4.15e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 27.2     |
| loss      | -3.88    |
| loss_q0   | -3.62    |
| loss_q1   | -3.97    |
| loss_q2   | -3.96    |
| loss_q3   | -3.98    |
| samples   | 4.99e+06 |
| step      | 4.16e+05 |
------------------------
------------------------
| grad_norm | 28.1     |
| loss      | -3.94    |
| loss_q0   | -3.68    |
| loss_q1   | -4.02    |
| loss_q2   | -4.05    |
| loss_q3   | -4.02    |
| samples   | 5e+06    |
| step      | 4.17e+05 |
------------------------
------------------------
| grad_norm | 27.4     |
| loss      | -3.95    |
| loss_q0   | -3.66    |
| loss_q1   | -4.04    |
| loss_q2   | -4.04    |
| loss_q3   | -4.05    |
| samples   | 5.02e+06 |
| step      | 4.18e+05 |
------------------------
------------------------
| grad_norm | 26.9     |
| loss      | -3.93    |
| loss_q0   | -3.7     |
| loss_q1   | -4       |
| loss_q2   | -4.03    |
| loss_q3   | -3.99    |
| samples   | 5.03e+06 |
| step      | 4.19e+05 |
------------------------
------------------------
| grad_norm | 27       |
| loss      | -3.91    |
| loss_q0   | -3.73    |
| loss_q1   | -4       |
| loss_q2   | -3.97    |
| loss_q3   | -3.96    |
| samples   | 5.04e+06 |
| step      | 4.2e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 28.3     |
| loss      | -3.94    |
| loss_q0   | -3.7     |
| loss_q1   | -3.98    |
| loss_q2   | -4.03    |
| loss_q3   | -4.04    |
| samples   | 5.05e+06 |
| step      | 4.21e+05 |
------------------------
------------------------
| grad_norm | 27.8     |
| loss      | -3.94    |
| loss_q0   | -3.72    |
| loss_q1   | -4.02    |
| loss_q2   | -4.03    |
| loss_q3   | -3.99    |
| samples   | 5.06e+06 |
| step      | 4.22e+05 |
------------------------
------------------------
| grad_norm | 26.9     |
| loss      | -3.91    |
| loss_q0   | -3.68    |
| loss_q1   | -4       |
| loss_q2   | -3.98    |
| loss_q3   | -3.98    |
| samples   | 5.08e+06 |
| step      | 4.23e+05 |
------------------------
------------------------
| grad_norm | 26.2     |
| loss      | -4.01    |
| loss_q0   | -3.79    |
| loss_q1   | -4.12    |
| loss_q2   | -4.07    |
| loss_q3   | -4.07    |
| samples   | 5.09e+06 |
| step      | 4.24e+05 |
------------------------
------------------------
| grad_norm | 29.3     |
| loss      | -3.87    |
| loss_q0   | -3.58    |
| loss_q1   | -3.95    |
| loss_q2   | -4.02    |
| loss_q3   | -3.93    |
| samples   | 5.1e+06  |
| step      | 4.25e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 26.1     |
| loss      | -3.92    |
| loss_q0   | -3.69    |
| loss_q1   | -3.99    |
| loss_q2   | -4.02    |
| loss_q3   | -4       |
| samples   | 5.11e+06 |
| step      | 4.26e+05 |
------------------------
------------------------
| grad_norm | 29.7     |
| loss      | -3.95    |
| loss_q0   | -3.67    |
| loss_q1   | -4.03    |
| loss_q2   | -4.07    |
| loss_q3   | -4.04    |
| samples   | 5.12e+06 |
| step      | 4.27e+05 |
------------------------
------------------------
| grad_norm | 27.2     |
| loss      | -3.88    |
| loss_q0   | -3.65    |
| loss_q1   | -3.93    |
| loss_q2   | -3.94    |
| loss_q3   | -4.01    |
| samples   | 5.14e+06 |
| step      | 4.28e+05 |
------------------------
------------------------
| grad_norm | 26       |
| loss      | -3.94    |
| loss_q0   | -3.68    |
| loss_q1   | -3.97    |
| loss_q2   | -4.04    |
| loss_q3   | -4.06    |
| samples   | 5.15e+06 |
| step      | 4.29e+05 |
------------------------
------------------------
| grad_norm | 27       |
| loss      | -4.02    |
| loss_q0   | -3.81    |
| loss_q1   | -4.11    |
| loss_q2   | -4.09    |
| loss_q3   | -4.1     |
| samples   | 5.16e+06 |
| step      | 4.3e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 28.1     |
| loss      | -3.94    |
| loss_q0   | -3.7     |
| loss_q1   | -4       |
| loss_q2   | -4.01    |
| loss_q3   | -4.03    |
| samples   | 5.17e+06 |
| step      | 4.31e+05 |
------------------------
------------------------
| grad_norm | 27.5     |
| loss      | -4.01    |
| loss_q0   | -3.76    |
| loss_q1   | -4.09    |
| loss_q2   | -4.11    |
| loss_q3   | -4.06    |
| samples   | 5.18e+06 |
| step      | 4.32e+05 |
------------------------
------------------------
| grad_norm | 27       |
| loss      | -3.94    |
| loss_q0   | -3.69    |
| loss_q1   | -4.02    |
| loss_q2   | -4.05    |
| loss_q3   | -4       |
| samples   | 5.2e+06  |
| step      | 4.33e+05 |
------------------------
------------------------
| grad_norm | 28.1     |
| loss      | -3.99    |
| loss_q0   | -3.75    |
| loss_q1   | -4.09    |
| loss_q2   | -4.03    |
| loss_q3   | -4.1     |
| samples   | 5.21e+06 |
| step      | 4.34e+05 |
------------------------
