Logging to /tmp/openai-2025-06-20-22-09-43-041437
World Size : 1
Creating conditional model and diffusion process...
/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
Creating data loader for medical images...
Training for modality_conversion
Starting training loop...
loading model from checkpoint: /home/prateek/controlled-diffusion/notebooks/models/model100000.pt...
loading optimizer state from checkpoint: /home/prateek/controlled-diffusion/notebooks/models/opt100000.pt
loading EMA from checkpoint: /home/prateek/controlled-diffusion/notebooks/models/ema_0.9999_100000.pt...
loading EMA from checkpoint: /home/prateek/controlled-diffusion/notebooks/models/ema_0.9999_100000.pt...
------------------------
| grad_norm | 2.44     |
| loss      | 3.25     |
| loss_q0   | 3.25     |
| loss_q1   | 3.25     |
| loss_q2   | 3.25     |
| loss_q3   | 3.25     |
| samples   | 1.2e+06  |
| step      | 1e+05    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 2.75     |
| loss      | 3.5      |
| loss_q0   | 3.48     |
| loss_q1   | 3.54     |
| loss_q2   | 3.5      |
| loss_q3   | 3.47     |
| samples   | 1.21e+06 |
| step      | 1.01e+05 |
------------------------
------------------------
| grad_norm | 2.46     |
| loss      | 3.16     |
| loss_q0   | 3.12     |
| loss_q1   | 3.18     |
| loss_q2   | 3.11     |
| loss_q3   | 3.22     |
| samples   | 1.22e+06 |
| step      | 1.02e+05 |
------------------------
------------------------
| grad_norm | 2.27     |
| loss      | 2.91     |
| loss_q0   | 2.91     |
| loss_q1   | 2.9      |
| loss_q2   | 2.91     |
| loss_q3   | 2.91     |
| samples   | 1.24e+06 |
| step      | 1.03e+05 |
------------------------
------------------------
| grad_norm | 2.11     |
| loss      | 2.69     |
| loss_q0   | 2.66     |
| loss_q1   | 2.7      |
| loss_q2   | 2.73     |
| loss_q3   | 2.67     |
| samples   | 1.25e+06 |
| step      | 1.04e+05 |
------------------------
------------------------
| grad_norm | 1.95     |
| loss      | 2.45     |
| loss_q0   | 2.42     |
| loss_q1   | 2.44     |
| loss_q2   | 2.45     |
| loss_q3   | 2.47     |
| samples   | 1.26e+06 |
| step      | 1.05e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.81     |
| loss      | 2.24     |
| loss_q0   | 2.24     |
| loss_q1   | 2.24     |
| loss_q2   | 2.23     |
| loss_q3   | 2.24     |
| samples   | 1.27e+06 |
| step      | 1.06e+05 |
------------------------
------------------------
| grad_norm | 1.75     |
| loss      | 2.11     |
| loss_q0   | 2.13     |
| loss_q1   | 2.09     |
| loss_q2   | 2.13     |
| loss_q3   | 2.1      |
| samples   | 1.28e+06 |
| step      | 1.07e+05 |
------------------------
------------------------
| grad_norm | 1.64     |
| loss      | 1.92     |
| loss_q0   | 1.92     |
| loss_q1   | 1.91     |
| loss_q2   | 1.92     |
| loss_q3   | 1.93     |
| samples   | 1.3e+06  |
| step      | 1.08e+05 |
------------------------
------------------------
| grad_norm | 1.57     |
| loss      | 1.78     |
| loss_q0   | 1.79     |
| loss_q1   | 1.8      |
| loss_q2   | 1.75     |
| loss_q3   | 1.77     |
| samples   | 1.31e+06 |
| step      | 1.09e+05 |
------------------------
------------------------
| grad_norm | 1.49     |
| loss      | 1.6      |
| loss_q0   | 1.61     |
| loss_q1   | 1.59     |
| loss_q2   | 1.59     |
| loss_q3   | 1.62     |
| samples   | 1.32e+06 |
| step      | 1.1e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.43     |
| loss      | 1.46     |
| loss_q0   | 1.49     |
| loss_q1   | 1.45     |
| loss_q2   | 1.44     |
| loss_q3   | 1.47     |
| samples   | 1.33e+06 |
| step      | 1.11e+05 |
------------------------
------------------------
| grad_norm | 1.37     |
| loss      | 1.32     |
| loss_q0   | 1.3      |
| loss_q1   | 1.31     |
| loss_q2   | 1.33     |
| loss_q3   | 1.33     |
| samples   | 1.34e+06 |
| step      | 1.12e+05 |
------------------------
------------------------
| grad_norm | 1.34     |
| loss      | 1.23     |
| loss_q0   | 1.25     |
| loss_q1   | 1.26     |
| loss_q2   | 1.19     |
| loss_q3   | 1.24     |
| samples   | 1.36e+06 |
| step      | 1.13e+05 |
------------------------
------------------------
| grad_norm | 1.3      |
| loss      | 1.08     |
| loss_q0   | 1.07     |
| loss_q1   | 1.08     |
| loss_q2   | 1.07     |
| loss_q3   | 1.08     |
| samples   | 1.37e+06 |
| step      | 1.14e+05 |
------------------------
------------------------
| grad_norm | 1.28     |
| loss      | 0.977    |
| loss_q0   | 0.985    |
| loss_q1   | 0.967    |
| loss_q2   | 0.977    |
| loss_q3   | 0.978    |
| samples   | 1.38e+06 |
| step      | 1.15e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.24     |
| loss      | 0.843    |
| loss_q0   | 0.848    |
| loss_q1   | 0.827    |
| loss_q2   | 0.858    |
| loss_q3   | 0.839    |
| samples   | 1.39e+06 |
| step      | 1.16e+05 |
------------------------
------------------------
| grad_norm | 1.23     |
| loss      | 0.733    |
| loss_q0   | 0.735    |
| loss_q1   | 0.726    |
| loss_q2   | 0.743    |
| loss_q3   | 0.73     |
| samples   | 1.4e+06  |
| step      | 1.17e+05 |
------------------------
------------------------
| grad_norm | 1.22     |
| loss      | 0.634    |
| loss_q0   | 0.641    |
| loss_q1   | 0.629    |
| loss_q2   | 0.642    |
| loss_q3   | 0.623    |
| samples   | 1.42e+06 |
| step      | 1.18e+05 |
------------------------
------------------------
| grad_norm | 1.19     |
| loss      | 0.505    |
| loss_q0   | 0.506    |
| loss_q1   | 0.488    |
| loss_q2   | 0.507    |
| loss_q3   | 0.52     |
| samples   | 1.43e+06 |
| step      | 1.19e+05 |
------------------------
------------------------
| grad_norm | 1.2      |
| loss      | 0.436    |
| loss_q0   | 0.45     |
| loss_q1   | 0.436    |
| loss_q2   | 0.416    |
| loss_q3   | 0.44     |
| samples   | 1.44e+06 |
| step      | 1.2e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.18     |
| loss      | 0.311    |
| loss_q0   | 0.31     |
| loss_q1   | 0.285    |
| loss_q2   | 0.306    |
| loss_q3   | 0.345    |
| samples   | 1.45e+06 |
| step      | 1.21e+05 |
------------------------
------------------------
| grad_norm | 1.19     |
| loss      | 0.214    |
| loss_q0   | 0.222    |
| loss_q1   | 0.22     |
| loss_q2   | 0.204    |
| loss_q3   | 0.208    |
| samples   | 1.46e+06 |
| step      | 1.22e+05 |
------------------------
------------------------
| grad_norm | 1.18     |
| loss      | 0.113    |
| loss_q0   | 0.0956   |
| loss_q1   | 0.116    |
| loss_q2   | 0.121    |
| loss_q3   | 0.119    |
| samples   | 1.48e+06 |
| step      | 1.23e+05 |
------------------------
-------------------------
| grad_norm | 1.18      |
| loss      | 0.0104    |
| loss_q0   | 0.0148    |
| loss_q1   | -0.000664 |
| loss_q2   | 0.0067    |
| loss_q3   | 0.0207    |
| samples   | 1.49e+06  |
| step      | 1.24e+05  |
-------------------------
------------------------
| grad_norm | 1.18     |
| loss      | -0.0984  |
| loss_q0   | -0.095   |
| loss_q1   | -0.108   |
| loss_q2   | -0.0994  |
| loss_q3   | -0.0916  |
| samples   | 1.5e+06  |
| step      | 1.25e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.19     |
| loss      | -0.19    |
| loss_q0   | -0.184   |
| loss_q1   | -0.186   |
| loss_q2   | -0.205   |
| loss_q3   | -0.184   |
| samples   | 1.51e+06 |
| step      | 1.26e+05 |
------------------------
------------------------
| grad_norm | 1.21     |
| loss      | -0.295   |
| loss_q0   | -0.299   |
| loss_q1   | -0.273   |
| loss_q2   | -0.307   |
| loss_q3   | -0.302   |
| samples   | 1.52e+06 |
| step      | 1.27e+05 |
------------------------
------------------------
| grad_norm | 1.2      |
| loss      | -0.392   |
| loss_q0   | -0.391   |
| loss_q1   | -0.408   |
| loss_q2   | -0.388   |
| loss_q3   | -0.381   |
| samples   | 1.54e+06 |
| step      | 1.28e+05 |
------------------------
------------------------
| grad_norm | 1.23     |
| loss      | -0.487   |
| loss_q0   | -0.492   |
| loss_q1   | -0.472   |
| loss_q2   | -0.499   |
| loss_q3   | -0.485   |
| samples   | 1.55e+06 |
| step      | 1.29e+05 |
------------------------
------------------------
| grad_norm | 1.25     |
| loss      | -0.596   |
| loss_q0   | -0.595   |
| loss_q1   | -0.602   |
| loss_q2   | -0.596   |
| loss_q3   | -0.59    |
| samples   | 1.56e+06 |
| step      | 1.3e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.24     |
| loss      | -0.678   |
| loss_q0   | -0.658   |
| loss_q1   | -0.684   |
| loss_q2   | -0.68    |
| loss_q3   | -0.691   |
| samples   | 1.57e+06 |
| step      | 1.31e+05 |
------------------------
------------------------
| grad_norm | 1.28     |
| loss      | -0.775   |
| loss_q0   | -0.765   |
| loss_q1   | -0.779   |
| loss_q2   | -0.777   |
| loss_q3   | -0.779   |
| samples   | 1.58e+06 |
| step      | 1.32e+05 |
------------------------
------------------------
| grad_norm | 1.31     |
| loss      | -0.9     |
| loss_q0   | -0.912   |
| loss_q1   | -0.904   |
| loss_q2   | -0.889   |
| loss_q3   | -0.894   |
| samples   | 1.6e+06  |
| step      | 1.33e+05 |
------------------------
------------------------
| grad_norm | 1.3      |
| loss      | -0.97    |
| loss_q0   | -0.954   |
| loss_q1   | -0.978   |
| loss_q2   | -0.986   |
| loss_q3   | -0.963   |
| samples   | 1.61e+06 |
| step      | 1.34e+05 |
------------------------
------------------------
| grad_norm | 1.4      |
| loss      | -1.07    |
| loss_q0   | -1.05    |
| loss_q1   | -1.09    |
| loss_q2   | -1.09    |
| loss_q3   | -1.07    |
| samples   | 1.62e+06 |
| step      | 1.35e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.45     |
| loss      | -1.17    |
| loss_q0   | -1.17    |
| loss_q1   | -1.17    |
| loss_q2   | -1.17    |
| loss_q3   | -1.17    |
| samples   | 1.63e+06 |
| step      | 1.36e+05 |
------------------------
------------------------
| grad_norm | 1.49     |
| loss      | -1.27    |
| loss_q0   | -1.27    |
| loss_q1   | -1.3     |
| loss_q2   | -1.27    |
| loss_q3   | -1.26    |
| samples   | 1.64e+06 |
| step      | 1.37e+05 |
------------------------
------------------------
| grad_norm | 1.49     |
| loss      | -1.36    |
| loss_q0   | -1.35    |
| loss_q1   | -1.37    |
| loss_q2   | -1.35    |
| loss_q3   | -1.36    |
| samples   | 1.66e+06 |
| step      | 1.38e+05 |
------------------------
------------------------
| grad_norm | 1.54     |
| loss      | -1.46    |
| loss_q0   | -1.44    |
| loss_q1   | -1.47    |
| loss_q2   | -1.48    |
| loss_q3   | -1.46    |
| samples   | 1.67e+06 |
| step      | 1.39e+05 |
------------------------
------------------------
| grad_norm | 1.72     |
| loss      | -1.54    |
| loss_q0   | -1.54    |
| loss_q1   | -1.55    |
| loss_q2   | -1.57    |
| loss_q3   | -1.53    |
| samples   | 1.68e+06 |
| step      | 1.4e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.84     |
| loss      | -1.65    |
| loss_q0   | -1.64    |
| loss_q1   | -1.66    |
| loss_q2   | -1.65    |
| loss_q3   | -1.66    |
| samples   | 1.69e+06 |
| step      | 1.41e+05 |
------------------------
------------------------
| grad_norm | 1.9      |
| loss      | -1.73    |
| loss_q0   | -1.75    |
| loss_q1   | -1.72    |
| loss_q2   | -1.76    |
| loss_q3   | -1.72    |
| samples   | 1.7e+06  |
| step      | 1.42e+05 |
------------------------
------------------------
| grad_norm | 2.02     |
| loss      | -1.84    |
| loss_q0   | -1.82    |
| loss_q1   | -1.84    |
| loss_q2   | -1.85    |
| loss_q3   | -1.84    |
| samples   | 1.72e+06 |
| step      | 1.43e+05 |
------------------------
------------------------
| grad_norm | 1.98     |
| loss      | -1.93    |
| loss_q0   | -1.91    |
| loss_q1   | -1.95    |
| loss_q2   | -1.96    |
| loss_q3   | -1.92    |
| samples   | 1.73e+06 |
| step      | 1.44e+05 |
------------------------
------------------------
| grad_norm | 2.45     |
| loss      | -2.03    |
| loss_q0   | -2       |
| loss_q1   | -2.04    |
| loss_q2   | -2.05    |
| loss_q3   | -2.02    |
| samples   | 1.74e+06 |
| step      | 1.45e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 2.37     |
| loss      | -2.11    |
| loss_q0   | -2.09    |
| loss_q1   | -2.11    |
| loss_q2   | -2.12    |
| loss_q3   | -2.1     |
| samples   | 1.75e+06 |
| step      | 1.46e+05 |
------------------------
------------------------
| grad_norm | 2.7      |
| loss      | -2.2     |
| loss_q0   | -2.18    |
| loss_q1   | -2.22    |
| loss_q2   | -2.2     |
| loss_q3   | -2.2     |
| samples   | 1.76e+06 |
| step      | 1.47e+05 |
------------------------
------------------------
| grad_norm | 2.87     |
| loss      | -2.3     |
| loss_q0   | -2.29    |
| loss_q1   | -2.31    |
| loss_q2   | -2.31    |
| loss_q3   | -2.29    |
| samples   | 1.78e+06 |
| step      | 1.48e+05 |
------------------------
------------------------
| grad_norm | 3.23     |
| loss      | -2.38    |
| loss_q0   | -2.36    |
| loss_q1   | -2.39    |
| loss_q2   | -2.39    |
| loss_q3   | -2.38    |
| samples   | 1.79e+06 |
| step      | 1.49e+05 |
------------------------
------------------------
| grad_norm | 3.36     |
| loss      | -2.47    |
| loss_q0   | -2.43    |
| loss_q1   | -2.48    |
| loss_q2   | -2.49    |
| loss_q3   | -2.47    |
| samples   | 1.8e+06  |
| step      | 1.5e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 3.86     |
| loss      | -2.54    |
| loss_q0   | -2.51    |
| loss_q1   | -2.55    |
| loss_q2   | -2.55    |
| loss_q3   | -2.56    |
| samples   | 1.81e+06 |
| step      | 1.51e+05 |
------------------------
------------------------
| grad_norm | 3.78     |
| loss      | -2.65    |
| loss_q0   | -2.61    |
| loss_q1   | -2.67    |
| loss_q2   | -2.66    |
| loss_q3   | -2.64    |
| samples   | 1.82e+06 |
| step      | 1.52e+05 |
------------------------
------------------------
| grad_norm | 4.18     |
| loss      | -2.71    |
| loss_q0   | -2.67    |
| loss_q1   | -2.73    |
| loss_q2   | -2.74    |
| loss_q3   | -2.72    |
| samples   | 1.84e+06 |
| step      | 1.53e+05 |
------------------------
------------------------
| grad_norm | 5.01     |
| loss      | -2.81    |
| loss_q0   | -2.76    |
| loss_q1   | -2.83    |
| loss_q2   | -2.81    |
| loss_q3   | -2.82    |
| samples   | 1.85e+06 |
| step      | 1.54e+05 |
------------------------
------------------------
| grad_norm | 5.31     |
| loss      | -2.86    |
| loss_q0   | -2.83    |
| loss_q1   | -2.88    |
| loss_q2   | -2.89    |
| loss_q3   | -2.86    |
| samples   | 1.86e+06 |
| step      | 1.55e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 5.68     |
| loss      | -2.95    |
| loss_q0   | -2.9     |
| loss_q1   | -2.98    |
| loss_q2   | -2.97    |
| loss_q3   | -2.96    |
| samples   | 1.87e+06 |
| step      | 1.56e+05 |
------------------------
------------------------
| grad_norm | 6.3      |
| loss      | -3.02    |
| loss_q0   | -2.96    |
| loss_q1   | -3.03    |
| loss_q2   | -3.03    |
| loss_q3   | -3.05    |
| samples   | 1.88e+06 |
| step      | 1.57e+05 |
------------------------
------------------------
| grad_norm | 6.92     |
| loss      | -3.07    |
| loss_q0   | -3.02    |
| loss_q1   | -3.08    |
| loss_q2   | -3.1     |
| loss_q3   | -3.09    |
| samples   | 1.9e+06  |
| step      | 1.58e+05 |
------------------------
------------------------
| grad_norm | 7.55     |
| loss      | -3.17    |
| loss_q0   | -3.1     |
| loss_q1   | -3.18    |
| loss_q2   | -3.19    |
| loss_q3   | -3.21    |
| samples   | 1.91e+06 |
| step      | 1.59e+05 |
------------------------
------------------------
| grad_norm | 7.33     |
| loss      | -3.25    |
| loss_q0   | -3.18    |
| loss_q1   | -3.29    |
| loss_q2   | -3.27    |
| loss_q3   | -3.27    |
| samples   | 1.92e+06 |
| step      | 1.6e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 8.84     |
| loss      | -3.27    |
| loss_q0   | -3.19    |
| loss_q1   | -3.29    |
| loss_q2   | -3.31    |
| loss_q3   | -3.3     |
| samples   | 1.93e+06 |
| step      | 1.61e+05 |
------------------------
------------------------
| grad_norm | 8.93     |
| loss      | -3.33    |
| loss_q0   | -3.25    |
| loss_q1   | -3.35    |
| loss_q2   | -3.39    |
| loss_q3   | -3.34    |
| samples   | 1.94e+06 |
| step      | 1.62e+05 |
------------------------
------------------------
| grad_norm | 10.1     |
| loss      | -3.39    |
| loss_q0   | -3.32    |
| loss_q1   | -3.42    |
| loss_q2   | -3.42    |
| loss_q3   | -3.42    |
| samples   | 1.96e+06 |
| step      | 1.63e+05 |
------------------------
------------------------
| grad_norm | 10.7     |
| loss      | -3.44    |
| loss_q0   | -3.33    |
| loss_q1   | -3.49    |
| loss_q2   | -3.44    |
| loss_q3   | -3.48    |
| samples   | 1.97e+06 |
| step      | 1.64e+05 |
------------------------
------------------------
| grad_norm | 11.5     |
| loss      | -3.49    |
| loss_q0   | -3.39    |
| loss_q1   | -3.51    |
| loss_q2   | -3.55    |
| loss_q3   | -3.49    |
| samples   | 1.98e+06 |
| step      | 1.65e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 12.7     |
| loss      | -3.53    |
| loss_q0   | -3.42    |
| loss_q1   | -3.57    |
| loss_q2   | -3.59    |
| loss_q3   | -3.54    |
| samples   | 1.99e+06 |
| step      | 1.66e+05 |
------------------------
------------------------
| grad_norm | 11.6     |
| loss      | -3.51    |
| loss_q0   | -3.37    |
| loss_q1   | -3.55    |
| loss_q2   | -3.58    |
| loss_q3   | -3.56    |
| samples   | 2e+06    |
| step      | 1.67e+05 |
------------------------
------------------------
| grad_norm | 14.3     |
| loss      | -3.55    |
| loss_q0   | -3.43    |
| loss_q1   | -3.57    |
| loss_q2   | -3.6     |
| loss_q3   | -3.59    |
| samples   | 2.02e+06 |
| step      | 1.68e+05 |
------------------------
------------------------
| grad_norm | 14       |
| loss      | -3.62    |
| loss_q0   | -3.51    |
| loss_q1   | -3.65    |
| loss_q2   | -3.66    |
| loss_q3   | -3.66    |
| samples   | 2.03e+06 |
| step      | 1.69e+05 |
------------------------
------------------------
| grad_norm | 14.3     |
| loss      | -3.64    |
| loss_q0   | -3.52    |
| loss_q1   | -3.69    |
| loss_q2   | -3.69    |
| loss_q3   | -3.68    |
| samples   | 2.04e+06 |
| step      | 1.7e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 16.5     |
| loss      | -3.59    |
| loss_q0   | -3.44    |
| loss_q1   | -3.62    |
| loss_q2   | -3.68    |
| loss_q3   | -3.64    |
| samples   | 2.05e+06 |
| step      | 1.71e+05 |
------------------------
------------------------
| grad_norm | 15.4     |
| loss      | -3.64    |
| loss_q0   | -3.46    |
| loss_q1   | -3.68    |
| loss_q2   | -3.7     |
| loss_q3   | -3.7     |
| samples   | 2.06e+06 |
| step      | 1.72e+05 |
------------------------
------------------------
| grad_norm | 16.3     |
| loss      | -3.64    |
| loss_q0   | -3.44    |
| loss_q1   | -3.7     |
| loss_q2   | -3.71    |
| loss_q3   | -3.69    |
| samples   | 2.08e+06 |
| step      | 1.73e+05 |
------------------------
------------------------
| grad_norm | 16.4     |
| loss      | -3.69    |
| loss_q0   | -3.53    |
| loss_q1   | -3.71    |
| loss_q2   | -3.76    |
| loss_q3   | -3.75    |
| samples   | 2.09e+06 |
| step      | 1.74e+05 |
------------------------
------------------------
| grad_norm | 17.6     |
| loss      | -3.68    |
| loss_q0   | -3.55    |
| loss_q1   | -3.71    |
| loss_q2   | -3.73    |
| loss_q3   | -3.74    |
| samples   | 2.1e+06  |
| step      | 1.75e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 17.2     |
| loss      | -3.73    |
| loss_q0   | -3.58    |
| loss_q1   | -3.8     |
| loss_q2   | -3.79    |
| loss_q3   | -3.75    |
| samples   | 2.11e+06 |
| step      | 1.76e+05 |
------------------------
------------------------
| grad_norm | 19.4     |
| loss      | -3.72    |
| loss_q0   | -3.51    |
| loss_q1   | -3.8     |
| loss_q2   | -3.78    |
| loss_q3   | -3.78    |
| samples   | 2.12e+06 |
| step      | 1.77e+05 |
------------------------
------------------------
| grad_norm | 20       |
| loss      | -3.73    |
| loss_q0   | -3.56    |
| loss_q1   | -3.8     |
| loss_q2   | -3.78    |
| loss_q3   | -3.76    |
| samples   | 2.14e+06 |
| step      | 1.78e+05 |
------------------------
------------------------
| grad_norm | 19       |
| loss      | -3.7     |
| loss_q0   | -3.5     |
| loss_q1   | -3.73    |
| loss_q2   | -3.77    |
| loss_q3   | -3.8     |
| samples   | 2.15e+06 |
| step      | 1.79e+05 |
------------------------
------------------------
| grad_norm | 19.9     |
| loss      | -3.81    |
| loss_q0   | -3.68    |
| loss_q1   | -3.85    |
| loss_q2   | -3.85    |
| loss_q3   | -3.87    |
| samples   | 2.16e+06 |
| step      | 1.8e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 20.5     |
| loss      | -3.67    |
| loss_q0   | -3.46    |
| loss_q1   | -3.73    |
| loss_q2   | -3.76    |
| loss_q3   | -3.73    |
| samples   | 2.17e+06 |
| step      | 1.81e+05 |
------------------------
------------------------
| grad_norm | 21.6     |
| loss      | -3.71    |
| loss_q0   | -3.51    |
| loss_q1   | -3.81    |
| loss_q2   | -3.74    |
| loss_q3   | -3.76    |
| samples   | 2.18e+06 |
| step      | 1.82e+05 |
------------------------
------------------------
| grad_norm | 20.2     |
| loss      | -3.81    |
| loss_q0   | -3.62    |
| loss_q1   | -3.86    |
| loss_q2   | -3.85    |
| loss_q3   | -3.9     |
| samples   | 2.2e+06  |
| step      | 1.83e+05 |
------------------------
------------------------
| grad_norm | 20.8     |
| loss      | -3.71    |
| loss_q0   | -3.5     |
| loss_q1   | -3.79    |
| loss_q2   | -3.79    |
| loss_q3   | -3.73    |
| samples   | 2.21e+06 |
| step      | 1.84e+05 |
------------------------
------------------------
| grad_norm | 21.3     |
| loss      | -3.78    |
| loss_q0   | -3.59    |
| loss_q1   | -3.84    |
| loss_q2   | -3.86    |
| loss_q3   | -3.84    |
| samples   | 2.22e+06 |
| step      | 1.85e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 20.1     |
| loss      | -3.77    |
| loss_q0   | -3.58    |
| loss_q1   | -3.82    |
| loss_q2   | -3.85    |
| loss_q3   | -3.83    |
| samples   | 2.23e+06 |
| step      | 1.86e+05 |
------------------------
------------------------
| grad_norm | 21.6     |
| loss      | -3.67    |
| loss_q0   | -3.45    |
| loss_q1   | -3.7     |
| loss_q2   | -3.78    |
| loss_q3   | -3.76    |
| samples   | 2.24e+06 |
| step      | 1.87e+05 |
------------------------
------------------------
| grad_norm | 22.8     |
| loss      | -3.71    |
| loss_q0   | -3.51    |
| loss_q1   | -3.8     |
| loss_q2   | -3.8     |
| loss_q3   | -3.75    |
| samples   | 2.26e+06 |
| step      | 1.88e+05 |
------------------------
------------------------
| grad_norm | 21.9     |
| loss      | -3.7     |
| loss_q0   | -3.48    |
| loss_q1   | -3.77    |
| loss_q2   | -3.76    |
| loss_q3   | -3.79    |
| samples   | 2.27e+06 |
| step      | 1.89e+05 |
------------------------
------------------------
| grad_norm | 20.7     |
| loss      | -3.74    |
| loss_q0   | -3.54    |
| loss_q1   | -3.82    |
| loss_q2   | -3.8     |
| loss_q3   | -3.81    |
| samples   | 2.28e+06 |
| step      | 1.9e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.9     |
| loss      | -3.77    |
| loss_q0   | -3.55    |
| loss_q1   | -3.8     |
| loss_q2   | -3.87    |
| loss_q3   | -3.87    |
| samples   | 2.29e+06 |
| step      | 1.91e+05 |
------------------------
------------------------
| grad_norm | 23.2     |
| loss      | -3.78    |
| loss_q0   | -3.59    |
| loss_q1   | -3.82    |
| loss_q2   | -3.84    |
| loss_q3   | -3.87    |
| samples   | 2.3e+06  |
| step      | 1.92e+05 |
------------------------
------------------------
| grad_norm | 21.1     |
| loss      | -3.75    |
| loss_q0   | -3.56    |
| loss_q1   | -3.8     |
| loss_q2   | -3.82    |
| loss_q3   | -3.81    |
| samples   | 2.32e+06 |
| step      | 1.93e+05 |
------------------------
------------------------
| grad_norm | 22.5     |
| loss      | -3.75    |
| loss_q0   | -3.52    |
| loss_q1   | -3.8     |
| loss_q2   | -3.84    |
| loss_q3   | -3.85    |
| samples   | 2.33e+06 |
| step      | 1.94e+05 |
------------------------
------------------------
| grad_norm | 22.6     |
| loss      | -3.75    |
| loss_q0   | -3.51    |
| loss_q1   | -3.81    |
| loss_q2   | -3.85    |
| loss_q3   | -3.83    |
| samples   | 2.34e+06 |
| step      | 1.95e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 21.9     |
| loss      | -3.76    |
| loss_q0   | -3.57    |
| loss_q1   | -3.81    |
| loss_q2   | -3.87    |
| loss_q3   | -3.81    |
| samples   | 2.35e+06 |
| step      | 1.96e+05 |
------------------------
------------------------
| grad_norm | 22.2     |
| loss      | -3.77    |
| loss_q0   | -3.54    |
| loss_q1   | -3.86    |
| loss_q2   | -3.79    |
| loss_q3   | -3.9     |
| samples   | 2.36e+06 |
| step      | 1.97e+05 |
------------------------
------------------------
| grad_norm | 24.1     |
| loss      | -3.74    |
| loss_q0   | -3.5     |
| loss_q1   | -3.82    |
| loss_q2   | -3.81    |
| loss_q3   | -3.82    |
| samples   | 2.38e+06 |
| step      | 1.98e+05 |
------------------------
------------------------
| grad_norm | 21.9     |
| loss      | -3.69    |
| loss_q0   | -3.52    |
| loss_q1   | -3.73    |
| loss_q2   | -3.74    |
| loss_q3   | -3.77    |
| samples   | 2.39e+06 |
| step      | 1.99e+05 |
------------------------
------------------------
| grad_norm | 22.5     |
| loss      | -3.72    |
| loss_q0   | -3.5     |
| loss_q1   | -3.78    |
| loss_q2   | -3.79    |
| loss_q3   | -3.8     |
| samples   | 2.4e+06  |
| step      | 2e+05    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 24.3     |
| loss      | -3.75    |
| loss_q0   | -3.54    |
| loss_q1   | -3.81    |
| loss_q2   | -3.81    |
| loss_q3   | -3.84    |
| samples   | 2.41e+06 |
| step      | 2.01e+05 |
------------------------
------------------------
| grad_norm | 20.7     |
| loss      | -3.87    |
| loss_q0   | -3.71    |
| loss_q1   | -3.9     |
| loss_q2   | -3.94    |
| loss_q3   | -3.92    |
| samples   | 2.42e+06 |
| step      | 2.02e+05 |
------------------------
------------------------
| grad_norm | 24.1     |
| loss      | -3.79    |
| loss_q0   | -3.58    |
| loss_q1   | -3.89    |
| loss_q2   | -3.84    |
| loss_q3   | -3.83    |
| samples   | 2.44e+06 |
| step      | 2.03e+05 |
------------------------
------------------------
| grad_norm | 21.8     |
| loss      | -3.79    |
| loss_q0   | -3.59    |
| loss_q1   | -3.83    |
| loss_q2   | -3.86    |
| loss_q3   | -3.89    |
| samples   | 2.45e+06 |
| step      | 2.04e+05 |
------------------------
------------------------
| grad_norm | 23.8     |
| loss      | -3.78    |
| loss_q0   | -3.56    |
| loss_q1   | -3.84    |
| loss_q2   | -3.85    |
| loss_q3   | -3.84    |
| samples   | 2.46e+06 |
| step      | 2.05e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.1     |
| loss      | -3.77    |
| loss_q0   | -3.54    |
| loss_q1   | -3.79    |
| loss_q2   | -3.88    |
| loss_q3   | -3.86    |
| samples   | 2.47e+06 |
| step      | 2.06e+05 |
------------------------
------------------------
| grad_norm | 20.7     |
| loss      | -3.87    |
| loss_q0   | -3.66    |
| loss_q1   | -3.94    |
| loss_q2   | -3.94    |
| loss_q3   | -3.95    |
| samples   | 2.48e+06 |
| step      | 2.07e+05 |
------------------------
------------------------
| grad_norm | 23.7     |
| loss      | -3.76    |
| loss_q0   | -3.53    |
| loss_q1   | -3.8     |
| loss_q2   | -3.89    |
| loss_q3   | -3.82    |
| samples   | 2.5e+06  |
| step      | 2.08e+05 |
------------------------
------------------------
| grad_norm | 24.6     |
| loss      | -3.8     |
| loss_q0   | -3.59    |
| loss_q1   | -3.89    |
| loss_q2   | -3.86    |
| loss_q3   | -3.87    |
| samples   | 2.51e+06 |
| step      | 2.09e+05 |
------------------------
------------------------
| grad_norm | 24.5     |
| loss      | -3.87    |
| loss_q0   | -3.67    |
| loss_q1   | -3.94    |
| loss_q2   | -3.95    |
| loss_q3   | -3.92    |
| samples   | 2.52e+06 |
| step      | 2.1e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.9     |
| loss      | -3.81    |
| loss_q0   | -3.6     |
| loss_q1   | -3.89    |
| loss_q2   | -3.88    |
| loss_q3   | -3.87    |
| samples   | 2.53e+06 |
| step      | 2.11e+05 |
------------------------
------------------------
| grad_norm | 23.3     |
| loss      | -3.87    |
| loss_q0   | -3.68    |
| loss_q1   | -3.91    |
| loss_q2   | -3.94    |
| loss_q3   | -3.95    |
| samples   | 2.54e+06 |
| step      | 2.12e+05 |
------------------------
------------------------
| grad_norm | 23.1     |
| loss      | -3.83    |
| loss_q0   | -3.6     |
| loss_q1   | -3.93    |
| loss_q2   | -3.9     |
| loss_q3   | -3.89    |
| samples   | 2.56e+06 |
| step      | 2.13e+05 |
------------------------
------------------------
| grad_norm | 25.2     |
| loss      | -3.75    |
| loss_q0   | -3.48    |
| loss_q1   | -3.86    |
| loss_q2   | -3.84    |
| loss_q3   | -3.84    |
| samples   | 2.57e+06 |
| step      | 2.14e+05 |
------------------------
------------------------
| grad_norm | 23.3     |
| loss      | -3.85    |
| loss_q0   | -3.63    |
| loss_q1   | -3.88    |
| loss_q2   | -3.95    |
| loss_q3   | -3.92    |
| samples   | 2.58e+06 |
| step      | 2.15e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 25.1     |
| loss      | -3.84    |
| loss_q0   | -3.59    |
| loss_q1   | -3.95    |
| loss_q2   | -3.86    |
| loss_q3   | -3.96    |
| samples   | 2.59e+06 |
| step      | 2.16e+05 |
------------------------
------------------------
| grad_norm | 24.3     |
| loss      | -3.83    |
| loss_q0   | -3.63    |
| loss_q1   | -3.87    |
| loss_q2   | -3.92    |
| loss_q3   | -3.88    |
| samples   | 2.6e+06  |
| step      | 2.17e+05 |
------------------------
------------------------
| grad_norm | 22.3     |
| loss      | -3.75    |
| loss_q0   | -3.53    |
| loss_q1   | -3.82    |
| loss_q2   | -3.82    |
| loss_q3   | -3.81    |
| samples   | 2.62e+06 |
| step      | 2.18e+05 |
------------------------
------------------------
| grad_norm | 25.4     |
| loss      | -3.83    |
| loss_q0   | -3.6     |
| loss_q1   | -3.87    |
| loss_q2   | -3.93    |
| loss_q3   | -3.93    |
| samples   | 2.63e+06 |
| step      | 2.19e+05 |
------------------------
------------------------
| grad_norm | 26       |
| loss      | -3.84    |
| loss_q0   | -3.65    |
| loss_q1   | -3.87    |
| loss_q2   | -3.93    |
| loss_q3   | -3.92    |
| samples   | 2.64e+06 |
| step      | 2.2e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.7     |
| loss      | -3.83    |
| loss_q0   | -3.59    |
| loss_q1   | -3.9     |
| loss_q2   | -3.9     |
| loss_q3   | -3.93    |
| samples   | 2.65e+06 |
| step      | 2.21e+05 |
------------------------
------------------------
| grad_norm | 25.9     |
| loss      | -3.72    |
| loss_q0   | -3.46    |
| loss_q1   | -3.81    |
| loss_q2   | -3.79    |
| loss_q3   | -3.8     |
| samples   | 2.66e+06 |
| step      | 2.22e+05 |
------------------------
------------------------
| grad_norm | 23.7     |
| loss      | -3.79    |
| loss_q0   | -3.58    |
| loss_q1   | -3.83    |
| loss_q2   | -3.89    |
| loss_q3   | -3.87    |
| samples   | 2.68e+06 |
| step      | 2.23e+05 |
------------------------
------------------------
| grad_norm | 22.8     |
| loss      | -3.78    |
| loss_q0   | -3.58    |
| loss_q1   | -3.84    |
| loss_q2   | -3.85    |
| loss_q3   | -3.87    |
| samples   | 2.69e+06 |
| step      | 2.24e+05 |
------------------------
------------------------
| grad_norm | 23.8     |
| loss      | -3.82    |
| loss_q0   | -3.57    |
| loss_q1   | -3.87    |
| loss_q2   | -3.92    |
| loss_q3   | -3.89    |
| samples   | 2.7e+06  |
| step      | 2.25e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.7     |
| loss      | -3.82    |
| loss_q0   | -3.64    |
| loss_q1   | -3.91    |
| loss_q2   | -3.89    |
| loss_q3   | -3.85    |
| samples   | 2.71e+06 |
| step      | 2.26e+05 |
------------------------
------------------------
| grad_norm | 25.1     |
| loss      | -3.82    |
| loss_q0   | -3.59    |
| loss_q1   | -3.89    |
| loss_q2   | -3.94    |
| loss_q3   | -3.87    |
| samples   | 2.72e+06 |
| step      | 2.27e+05 |
------------------------
------------------------
| grad_norm | 22.9     |
| loss      | -3.82    |
| loss_q0   | -3.59    |
| loss_q1   | -3.91    |
| loss_q2   | -3.88    |
| loss_q3   | -3.89    |
| samples   | 2.74e+06 |
| step      | 2.28e+05 |
------------------------
------------------------
| grad_norm | 24.3     |
| loss      | -3.79    |
| loss_q0   | -3.54    |
| loss_q1   | -3.85    |
| loss_q2   | -3.9     |
| loss_q3   | -3.89    |
| samples   | 2.75e+06 |
| step      | 2.29e+05 |
------------------------
------------------------
| grad_norm | 24.7     |
| loss      | -3.75    |
| loss_q0   | -3.54    |
| loss_q1   | -3.81    |
| loss_q2   | -3.84    |
| loss_q3   | -3.81    |
| samples   | 2.76e+06 |
| step      | 2.3e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 24.9     |
| loss      | -3.82    |
| loss_q0   | -3.61    |
| loss_q1   | -3.89    |
| loss_q2   | -3.88    |
| loss_q3   | -3.89    |
| samples   | 2.77e+06 |
| step      | 2.31e+05 |
------------------------
------------------------
| grad_norm | 22.8     |
| loss      | -3.78    |
| loss_q0   | -3.57    |
| loss_q1   | -3.85    |
| loss_q2   | -3.86    |
| loss_q3   | -3.85    |
| samples   | 2.78e+06 |
| step      | 2.32e+05 |
------------------------
------------------------
| grad_norm | 23.8     |
| loss      | -3.85    |
| loss_q0   | -3.66    |
| loss_q1   | -3.92    |
| loss_q2   | -3.91    |
| loss_q3   | -3.91    |
| samples   | 2.8e+06  |
| step      | 2.33e+05 |
------------------------
------------------------
| grad_norm | 24.8     |
| loss      | -3.77    |
| loss_q0   | -3.48    |
| loss_q1   | -3.8     |
| loss_q2   | -3.92    |
| loss_q3   | -3.89    |
| samples   | 2.81e+06 |
| step      | 2.34e+05 |
------------------------
------------------------
| grad_norm | 23.3     |
| loss      | -3.91    |
| loss_q0   | -3.75    |
| loss_q1   | -3.93    |
| loss_q2   | -4.01    |
| loss_q3   | -3.97    |
| samples   | 2.82e+06 |
| step      | 2.35e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.3     |
| loss      | -3.76    |
| loss_q0   | -3.52    |
| loss_q1   | -3.85    |
| loss_q2   | -3.85    |
| loss_q3   | -3.82    |
| samples   | 2.83e+06 |
| step      | 2.36e+05 |
------------------------
------------------------
| grad_norm | 22.8     |
| loss      | -3.78    |
| loss_q0   | -3.56    |
| loss_q1   | -3.87    |
| loss_q2   | -3.85    |
| loss_q3   | -3.86    |
| samples   | 2.84e+06 |
| step      | 2.37e+05 |
------------------------
------------------------
| grad_norm | 22.3     |
| loss      | -3.86    |
| loss_q0   | -3.61    |
| loss_q1   | -3.95    |
| loss_q2   | -3.93    |
| loss_q3   | -3.93    |
| samples   | 2.86e+06 |
| step      | 2.38e+05 |
------------------------
------------------------
| grad_norm | 25.5     |
| loss      | -3.81    |
| loss_q0   | -3.57    |
| loss_q1   | -3.9     |
| loss_q2   | -3.9     |
| loss_q3   | -3.85    |
| samples   | 2.87e+06 |
| step      | 2.39e+05 |
------------------------
------------------------
| grad_norm | 24.3     |
| loss      | -3.71    |
| loss_q0   | -3.5     |
| loss_q1   | -3.76    |
| loss_q2   | -3.79    |
| loss_q3   | -3.81    |
| samples   | 2.88e+06 |
| step      | 2.4e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.5     |
| loss      | -3.75    |
| loss_q0   | -3.53    |
| loss_q1   | -3.82    |
| loss_q2   | -3.83    |
| loss_q3   | -3.83    |
| samples   | 2.89e+06 |
| step      | 2.41e+05 |
------------------------
------------------------
| grad_norm | 22.7     |
| loss      | -3.86    |
| loss_q0   | -3.64    |
| loss_q1   | -3.89    |
| loss_q2   | -3.94    |
| loss_q3   | -3.95    |
| samples   | 2.9e+06  |
| step      | 2.42e+05 |
------------------------
------------------------
| grad_norm | 23.1     |
| loss      | -3.79    |
| loss_q0   | -3.55    |
| loss_q1   | -3.88    |
| loss_q2   | -3.88    |
| loss_q3   | -3.84    |
| samples   | 2.92e+06 |
| step      | 2.43e+05 |
------------------------
------------------------
| grad_norm | 23.8     |
| loss      | -3.81    |
| loss_q0   | -3.56    |
| loss_q1   | -3.9     |
| loss_q2   | -3.88    |
| loss_q3   | -3.9     |
| samples   | 2.93e+06 |
| step      | 2.44e+05 |
------------------------
------------------------
| grad_norm | 22.8     |
| loss      | -3.82    |
| loss_q0   | -3.58    |
| loss_q1   | -3.87    |
| loss_q2   | -3.9     |
| loss_q3   | -3.95    |
| samples   | 2.94e+06 |
| step      | 2.45e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 24.5     |
| loss      | -3.88    |
| loss_q0   | -3.66    |
| loss_q1   | -3.89    |
| loss_q2   | -3.95    |
| loss_q3   | -4       |
| samples   | 2.95e+06 |
| step      | 2.46e+05 |
------------------------
------------------------
| grad_norm | 23.5     |
| loss      | -3.84    |
| loss_q0   | -3.62    |
| loss_q1   | -3.9     |
| loss_q2   | -3.88    |
| loss_q3   | -3.95    |
| samples   | 2.96e+06 |
| step      | 2.47e+05 |
------------------------
------------------------
| grad_norm | 23.1     |
| loss      | -3.85    |
| loss_q0   | -3.64    |
| loss_q1   | -3.89    |
| loss_q2   | -3.95    |
| loss_q3   | -3.93    |
| samples   | 2.98e+06 |
| step      | 2.48e+05 |
------------------------
------------------------
| grad_norm | 24       |
| loss      | -3.81    |
| loss_q0   | -3.62    |
| loss_q1   | -3.85    |
| loss_q2   | -3.88    |
| loss_q3   | -3.87    |
| samples   | 2.99e+06 |
| step      | 2.49e+05 |
------------------------
------------------------
| grad_norm | 22.8     |
| loss      | -3.76    |
| loss_q0   | -3.53    |
| loss_q1   | -3.81    |
| loss_q2   | -3.84    |
| loss_q3   | -3.84    |
| samples   | 3e+06    |
| step      | 2.5e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.3     |
| loss      | -3.9     |
| loss_q0   | -3.69    |
| loss_q1   | -3.98    |
| loss_q2   | -3.96    |
| loss_q3   | -3.97    |
| samples   | 3.01e+06 |
| step      | 2.51e+05 |
------------------------
------------------------
| grad_norm | 23.6     |
| loss      | -3.85    |
| loss_q0   | -3.59    |
| loss_q1   | -3.95    |
| loss_q2   | -3.91    |
| loss_q3   | -3.95    |
| samples   | 3.02e+06 |
| step      | 2.52e+05 |
------------------------
------------------------
| grad_norm | 23.4     |
| loss      | -3.8     |
| loss_q0   | -3.54    |
| loss_q1   | -3.89    |
| loss_q2   | -3.91    |
| loss_q3   | -3.87    |
| samples   | 3.04e+06 |
| step      | 2.53e+05 |
------------------------
------------------------
| grad_norm | 22       |
| loss      | -3.9     |
| loss_q0   | -3.69    |
| loss_q1   | -3.95    |
| loss_q2   | -3.99    |
| loss_q3   | -3.98    |
| samples   | 3.05e+06 |
| step      | 2.54e+05 |
------------------------
------------------------
| grad_norm | 25.1     |
| loss      | -3.83    |
| loss_q0   | -3.55    |
| loss_q1   | -3.91    |
| loss_q2   | -3.96    |
| loss_q3   | -3.92    |
| samples   | 3.06e+06 |
| step      | 2.55e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.5     |
| loss      | -3.77    |
| loss_q0   | -3.54    |
| loss_q1   | -3.86    |
| loss_q2   | -3.85    |
| loss_q3   | -3.83    |
| samples   | 3.07e+06 |
| step      | 2.56e+05 |
------------------------
------------------------
| grad_norm | 22.4     |
| loss      | -3.85    |
| loss_q0   | -3.62    |
| loss_q1   | -3.9     |
| loss_q2   | -3.91    |
| loss_q3   | -3.96    |
| samples   | 3.08e+06 |
| step      | 2.57e+05 |
------------------------
------------------------
| grad_norm | 24.8     |
| loss      | -3.77    |
| loss_q0   | -3.51    |
| loss_q1   | -3.84    |
| loss_q2   | -3.83    |
| loss_q3   | -3.89    |
| samples   | 3.1e+06  |
| step      | 2.58e+05 |
------------------------
------------------------
| grad_norm | 20.6     |
| loss      | -3.89    |
| loss_q0   | -3.67    |
| loss_q1   | -3.91    |
| loss_q2   | -3.97    |
| loss_q3   | -4       |
| samples   | 3.11e+06 |
| step      | 2.59e+05 |
------------------------
------------------------
| grad_norm | 22.6     |
| loss      | -3.86    |
| loss_q0   | -3.63    |
| loss_q1   | -3.96    |
| loss_q2   | -3.92    |
| loss_q3   | -3.95    |
| samples   | 3.12e+06 |
| step      | 2.6e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 24.7     |
| loss      | -3.82    |
| loss_q0   | -3.61    |
| loss_q1   | -3.88    |
| loss_q2   | -3.89    |
| loss_q3   | -3.89    |
| samples   | 3.13e+06 |
| step      | 2.61e+05 |
------------------------
------------------------
| grad_norm | 23       |
| loss      | -3.83    |
| loss_q0   | -3.59    |
| loss_q1   | -3.88    |
| loss_q2   | -3.91    |
| loss_q3   | -3.93    |
| samples   | 3.14e+06 |
| step      | 2.62e+05 |
------------------------
------------------------
| grad_norm | 24       |
| loss      | -3.87    |
| loss_q0   | -3.64    |
| loss_q1   | -3.92    |
| loss_q2   | -3.95    |
| loss_q3   | -3.96    |
| samples   | 3.16e+06 |
| step      | 2.63e+05 |
------------------------
------------------------
| grad_norm | 22.4     |
| loss      | -3.84    |
| loss_q0   | -3.65    |
| loss_q1   | -3.93    |
| loss_q2   | -3.9     |
| loss_q3   | -3.89    |
| samples   | 3.17e+06 |
| step      | 2.64e+05 |
------------------------
------------------------
| grad_norm | 23.9     |
| loss      | -3.9     |
| loss_q0   | -3.69    |
| loss_q1   | -3.94    |
| loss_q2   | -3.99    |
| loss_q3   | -3.99    |
| samples   | 3.18e+06 |
| step      | 2.65e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.8     |
| loss      | -3.84    |
| loss_q0   | -3.59    |
| loss_q1   | -3.94    |
| loss_q2   | -3.92    |
| loss_q3   | -3.91    |
| samples   | 3.19e+06 |
| step      | 2.66e+05 |
------------------------
------------------------
| grad_norm | 23.3     |
| loss      | -3.91    |
| loss_q0   | -3.74    |
| loss_q1   | -3.95    |
| loss_q2   | -4       |
| loss_q3   | -3.97    |
| samples   | 3.2e+06  |
| step      | 2.67e+05 |
------------------------
------------------------
| grad_norm | 24.5     |
| loss      | -3.87    |
| loss_q0   | -3.68    |
| loss_q1   | -3.89    |
| loss_q2   | -3.96    |
| loss_q3   | -3.96    |
| samples   | 3.22e+06 |
| step      | 2.68e+05 |
------------------------
------------------------
| grad_norm | 23.1     |
| loss      | -3.89    |
| loss_q0   | -3.69    |
| loss_q1   | -4       |
| loss_q2   | -3.96    |
| loss_q3   | -3.93    |
| samples   | 3.23e+06 |
| step      | 2.69e+05 |
------------------------
------------------------
| grad_norm | 25.3     |
| loss      | -3.75    |
| loss_q0   | -3.48    |
| loss_q1   | -3.83    |
| loss_q2   | -3.86    |
| loss_q3   | -3.85    |
| samples   | 3.24e+06 |
| step      | 2.7e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.5     |
| loss      | -3.78    |
| loss_q0   | -3.5     |
| loss_q1   | -3.82    |
| loss_q2   | -3.9     |
| loss_q3   | -3.88    |
| samples   | 3.25e+06 |
| step      | 2.71e+05 |
------------------------
------------------------
| grad_norm | 22.6     |
| loss      | -3.88    |
| loss_q0   | -3.68    |
| loss_q1   | -3.95    |
| loss_q2   | -3.92    |
| loss_q3   | -3.95    |
| samples   | 3.26e+06 |
| step      | 2.72e+05 |
------------------------
------------------------
| grad_norm | 21.9     |
| loss      | -3.89    |
| loss_q0   | -3.67    |
| loss_q1   | -3.98    |
| loss_q2   | -3.99    |
| loss_q3   | -3.93    |
| samples   | 3.28e+06 |
| step      | 2.73e+05 |
------------------------
------------------------
| grad_norm | 22.7     |
| loss      | -3.82    |
| loss_q0   | -3.58    |
| loss_q1   | -3.89    |
| loss_q2   | -3.91    |
| loss_q3   | -3.91    |
| samples   | 3.29e+06 |
| step      | 2.74e+05 |
------------------------
------------------------
| grad_norm | 23.1     |
| loss      | -3.81    |
| loss_q0   | -3.56    |
| loss_q1   | -3.91    |
| loss_q2   | -3.86    |
| loss_q3   | -3.9     |
| samples   | 3.3e+06  |
| step      | 2.75e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.4     |
| loss      | -3.87    |
| loss_q0   | -3.63    |
| loss_q1   | -3.94    |
| loss_q2   | -3.96    |
| loss_q3   | -3.96    |
| samples   | 3.31e+06 |
| step      | 2.76e+05 |
------------------------
------------------------
| grad_norm | 24.2     |
| loss      | -3.84    |
| loss_q0   | -3.59    |
| loss_q1   | -3.92    |
| loss_q2   | -3.91    |
| loss_q3   | -3.93    |
| samples   | 3.32e+06 |
| step      | 2.77e+05 |
------------------------
------------------------
| grad_norm | 24.3     |
| loss      | -3.84    |
| loss_q0   | -3.6     |
| loss_q1   | -3.91    |
| loss_q2   | -3.95    |
| loss_q3   | -3.93    |
| samples   | 3.34e+06 |
| step      | 2.78e+05 |
------------------------
------------------------
| grad_norm | 21.6     |
| loss      | -3.84    |
| loss_q0   | -3.62    |
| loss_q1   | -3.92    |
| loss_q2   | -3.9     |
| loss_q3   | -3.92    |
| samples   | 3.35e+06 |
| step      | 2.79e+05 |
------------------------
------------------------
| grad_norm | 23.4     |
| loss      | -3.81    |
| loss_q0   | -3.59    |
| loss_q1   | -3.89    |
| loss_q2   | -3.87    |
| loss_q3   | -3.89    |
| samples   | 3.36e+06 |
| step      | 2.8e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 23.2     |
| loss      | -3.84    |
| loss_q0   | -3.62    |
| loss_q1   | -3.9     |
| loss_q2   | -3.94    |
| loss_q3   | -3.9     |
| samples   | 3.37e+06 |
| step      | 2.81e+05 |
------------------------
------------------------
| grad_norm | 21.7     |
| loss      | -3.81    |
| loss_q0   | -3.57    |
| loss_q1   | -3.89    |
| loss_q2   | -3.91    |
| loss_q3   | -3.87    |
| samples   | 3.38e+06 |
| step      | 2.82e+05 |
------------------------
------------------------
| grad_norm | 24.9     |
| loss      | -3.93    |
| loss_q0   | -3.73    |
| loss_q1   | -3.97    |
| loss_q2   | -4.04    |
| loss_q3   | -3.99    |
| samples   | 3.4e+06  |
| step      | 2.83e+05 |
------------------------
------------------------
| grad_norm | 23.4     |
| loss      | -3.86    |
| loss_q0   | -3.64    |
| loss_q1   | -3.92    |
| loss_q2   | -3.94    |
| loss_q3   | -3.96    |
| samples   | 3.41e+06 |
| step      | 2.84e+05 |
------------------------
------------------------
| grad_norm | 22.2     |
| loss      | -3.87    |
| loss_q0   | -3.7     |
| loss_q1   | -3.91    |
| loss_q2   | -3.91    |
| loss_q3   | -3.97    |
| samples   | 3.42e+06 |
| step      | 2.85e+05 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 22.6     |
| loss      | -3.94    |
| loss_q0   | -3.74    |
| loss_q1   | -3.99    |
| loss_q2   | -4.01    |
| loss_q3   | -4.01    |
| samples   | 3.43e+06 |
| step      | 2.86e+05 |
------------------------
------------------------
| grad_norm | 23       |
| loss      | -3.8     |
| loss_q0   | -3.6     |
| loss_q1   | -3.89    |
| loss_q2   | -3.87    |
| loss_q3   | -3.85    |
| samples   | 3.44e+06 |
| step      | 2.87e+05 |
------------------------
------------------------
| grad_norm | 23.3     |
| loss      | -3.94    |
| loss_q0   | -3.74    |
| loss_q1   | -4.03    |
| loss_q2   | -4       |
| loss_q3   | -3.97    |
| samples   | 3.46e+06 |
| step      | 2.88e+05 |
------------------------
------------------------
| grad_norm | 23.2     |
| loss      | -3.87    |
| loss_q0   | -3.62    |
| loss_q1   | -3.91    |
| loss_q2   | -3.98    |
| loss_q3   | -3.96    |
| samples   | 3.47e+06 |
| step      | 2.89e+05 |
------------------------
Traceback (most recent call last):
  File "train_ms.py", line 193, in <module>
    main()
  File "train_ms.py", line 102, in main
    run_training(args)
  File "train_ms.py", line 142, in run_training
    TrainLoop(
  File "/home/prateek/controlled-diffusion/improved_diffusion/train_util.py", line 178, in run_loop
    self.run_step(batch, cond)
  File "/home/prateek/controlled-diffusion/improved_diffusion/train_util.py", line 193, in run_step
    self.forward_backward(batch, cond, drop_condition)
  File "/home/prateek/controlled-diffusion/improved_diffusion/train_util.py", line 238, in forward_backward
    loss.backward()
  File "/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/prateek/anaconda3/envs/ms_diffusion/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1781002) is killed by signal: Killed. 
